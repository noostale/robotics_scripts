{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Robotics II\n",
    "\n",
    "Example: Two link planar robot\n",
    "\n",
    "General conrdinates $q$ = [$q_1$, $q_2$] = [$\\theta_1$, $\\theta_2$] so these are in the joint space.\n",
    "\n",
    "But often we have a task variable $R$ = [$x$, $y$] that rappresents the position of the end effector in the task space.\n",
    "\n",
    "If we compute the forward kinematics of a two link planar robot we can find the following equations:\n",
    "$$\n",
    "\\begin{cases}\n",
    "x = l_1 \\cos(\\theta_1) + l_2 \\cos(\\theta_1 + \\theta_2) \\\\\n",
    "y = l_1 \\sin(\\theta_1) + l_2 \\sin(\\theta_1 + \\theta_2)\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "So, as we can see this is a relation between the joint space and the task space.\n",
    "\n",
    "This means that we can create a function that maps the joint space to the task space and viceversa.\n",
    "\n",
    "$$\n",
    "R = f(q) = \\begin{bmatrix} l_1 \\cos(\\theta_1) + l_2 \\cos(\\theta_1 + \\theta_2) \\\\ l_1 \\sin(\\theta_1) + l_2 \\sin(\\theta_1 + \\theta_2) \\end{bmatrix} = \\begin{bmatrix} x \\\\ y \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Now, since we are interested in HOW THE TASK SPACE CHANGES when we move in the joint space, we can use the JACOBIAN MATRIX. This defines the differential relationship between the joint space and the task space.\n",
    "\n",
    "$$\n",
    "J(q) = \\frac{\\partial R}{\\partial q} = \\frac{\\partial f(q)}{\\partial q} =\n",
    "\\begin{bmatrix} \\frac{\\partial x}{\\partial q_1} & \\frac{\\partial x}{\\partial q_2} \\\\ \\frac{\\partial y}{\\partial q_1} & \\frac{\\partial y}{\\partial q_2} \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "So, computing the partial derivatives we get:\n",
    "\n",
    "$$\n",
    "J(q) = \\begin{bmatrix} -l_1 \\sin(\\theta_1) - l_2 \\sin(\\theta_1 + \\theta_2) & -l_2 \\sin(\\theta_1 + \\theta_2) \\\\ l_1 \\cos(\\theta_1) + l_2 \\cos(\\theta_1 + \\theta_2) & l_2 \\cos(\\theta_1 + \\theta_2) \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "This matrix is good since it exploits a new relation between the joint space and the task space:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix} \\dot{x} \\\\ \\dot{y} \\end{bmatrix} = J(q) \\begin{bmatrix} \\dot{q_1} \\\\ \\dot{q_2} \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "or, in a more compact form:\n",
    "\n",
    "$$\n",
    "\\dot{R} = J(q) \\dot{q}\n",
    "$$\n",
    "\n",
    "\n",
    "The primary control problem is: given a desired task space velocity $\\dot{R}_d$, find the joint space velocity $\\dot{q}$ that will generate it.\n",
    "\n",
    "$$\n",
    "J(q) \\dot{q} = \\dot{R}_d\n",
    "$$\n",
    "\n",
    "So, the solution is:\n",
    "\n",
    "$$\n",
    "\\dot{q} = J(q)^{-1} \\dot{R}_d\n",
    "$$\n",
    "\n",
    "But, since the Jacobian matrix is not always invertible, we need to use different approaches to solve this problem.\n",
    "\n",
    "Sometimes the generalized inverse is define as $K(q)$, so the solution becomes:\n",
    "\n",
    "$$\n",
    "\\dot{q} = K(q) \\dot{R}_d\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moore-Penrose Pseudoinverse\n",
    "\n",
    "The Moore-Penrose pseudoinverse is a generalization of the matrix inverse when the matrix is not square or not full rank.\n",
    "\n",
    "Starting from the relationship between $\\dot{R}$ and $\\dot{q}$ we can write:\n",
    "\n",
    "$$\n",
    "\\dot{q} = J(q)^{-1} \\dot{R}\n",
    "$$\n",
    "\n",
    "If we decide to use the Moore-Penrose we define the $J(q)^{-1}$ as $J^{+}(q)$, so the solution becomes:\n",
    "\n",
    "$$\n",
    "\\dot{q} = J^{+}(q) \\dot{R}\n",
    "$$\n",
    "\n",
    "The Moore-Penrose pseudoinverse is defined as:\n",
    "\n",
    "$$\n",
    "J^{+}(q) = J^T(q) (J(q) J^T(q))^{-1}\n",
    "$$\n",
    "\n",
    "So, the solution is:\n",
    "\n",
    "$$\n",
    "\\dot{q} = J^T(q) (J(q) J^T(q))^{-1} \\dot{R}\n",
    "$$\n",
    "\n",
    "## Weighted Pseudoinverse\n",
    "\n",
    "The weighted pseudoinverse is a generalization of the Moore-Penrose pseudoinverse that allows to give more importance to some joints than others.\n",
    "\n",
    "The weighted pseudoinverse is defined as:\n",
    "\n",
    "$$\n",
    "J^{+}(q) = J^T(q) (J(q) W(q) J^T(q))^{-1}\n",
    "$$\n",
    "\n",
    "where $W(q)$ is a diagonal matrix that contains the weights for each joint.\n",
    "\n",
    "The only difference between the weighted pseudoinverse and the Moore-Penrose pseudoinverse is the presence of the $W(q)$ matrix.\n",
    "\n",
    "So, the solution that gives us $\\dot{q}$ is:\n",
    "\n",
    "$$\n",
    "\\dot{q} = J^T(q) (J(q) W(q) J^T(q))^{-1} \\dot{R}\n",
    "$$\n",
    "\n",
    "## Damped Least Squares\n",
    "\n",
    "\n",
    "\n",
    "## Pseudoinverse and weighted pseudoinverse via Singular Value Decomposition\n",
    "\n",
    "SVD is a method to compute the pseudoinverse of a matrix, even if it is not square or full rank.\n",
    "\n",
    "The SVD of a matrix $J(q)$ is defined as:\n",
    "\n",
    "$$\n",
    "J(q) = U \\Sigma V^T\n",
    "$$\n",
    "\n",
    "where $U$ and $V$ are orthogonal matrices and $\\Sigma$ is a diagonal matrix.\n",
    "\n",
    "## Damped Least Squares via Singular Value Decomposition\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Null-Space Methods for Redundant Manipulators\n",
    "\n",
    "*from here on I am using J instead of J(q) for simplicity.*\n",
    "\n",
    "Usually, to solve a redundancy problem we can leverage on the inverse of the Jacobian matrix that gives us:\n",
    "\n",
    "$$\n",
    "\\dot{q} = J^{-1} \\dot{R}\n",
    "$$\n",
    "\n",
    "But, since the robot is redundant,we can add a null-space component that does not interfere with the primary task:\n",
    "\n",
    "$$\n",
    "\\dot{q} = J^{-1} \\dot{R} + (I - J^{-1} J) \\dot{q}_0\n",
    "$$\n",
    "\n",
    "where $\\dot{q}_0$ is the null-space velocity.\n",
    "\n",
    "Since the null-space component is not interfering with the primary task, we can use it to perform a secondary task. The choice of $\\dot{q}_0$ is arbitrary, usually we have a $\\dot{q}^{pref}_0$ that is the desired null-space velocity and this is usually done via a quadratic optimization problem.\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\min_{\\dot{\\mathbf{q}} \\in \\mathbb{R}^n} &\\quad \\frac{1}{2}\\left(\\dot{\\mathbf{q}} - \\dot{\\mathbf{q}}_0^\\text{pref}\\right)^T W \\left(\\dot{\\mathbf{q}} - \\dot{\\mathbf{q}}_0^\\text{pref}\\right) \\\\\n",
    "\\text{subject to} &\\quad J\\,\\dot{\\mathbf{q}} = \\dot{\\mathbf{r}},\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "How do we find the solution of an optimization problem that is subject to a constraint? We can use the Lagrange multipliers method.\n",
    "\n",
    "So we define the lagrangian:\n",
    "\n",
    "$$\n",
    "L(\\dot{\\mathbf{q}}, \\lambda) = \\frac{1}{2}\\left(\\dot{\\mathbf{q}} - \\dot{\\mathbf{q}}_0^\\text{pref}\\right)^T W \\left(\\dot{\\mathbf{q}} - \\dot{\\mathbf{q}}_0^\\text{pref}\\right) + \\lambda^T (J\\,\\dot{\\mathbf{q}} - \\dot{\\mathbf{r}})\n",
    "$$\n",
    "\n",
    "and we compute the gradient of the lagrangian:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\frac{\\partial L}{\\partial \\dot{\\mathbf{q}}} &= W \\left(\\dot{\\mathbf{q}} - \\dot{\\mathbf{q}}_0^\\text{pref}\\right) + J^T \\lambda \\\\\n",
    "\\frac{\\partial L}{\\partial \\lambda} &= J\\,\\dot{\\mathbf{q}} - \\dot{\\mathbf{r}}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Now we set the gradient to zero:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "W \\left(\\dot{\\mathbf{q}} - \\dot{\\mathbf{q}}_0^\\text{pref}\\right) + J^T \\lambda &= 0 \\\\\n",
    "J\\,\\dot{\\mathbf{q}} &= \\dot{\\mathbf{r}}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Now we can solve the first equation for $\\dot{\\mathbf{q}}$:\n",
    "\n",
    "$$\n",
    "\\dot{\\mathbf{q}} = W^{-1} J^T \\lambda + \\dot{\\mathbf{q}}_0^\\text{pref}\n",
    "$$\n",
    "\n",
    "and we can substitute this in the second equation:\n",
    "\n",
    "$$\n",
    "J\\, (W^{-1} J^T \\lambda + \\dot{\\mathbf{q}}_0^\\text{pref}) = \\dot{\\mathbf{r}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "J\\, W^{-1} J^T \\lambda + J\\, \\dot{\\mathbf{q}}_0^\\text{pref} = \\dot{\\mathbf{r}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "J\\, W^{-1} J^T \\lambda = \\dot{\\mathbf{r}} - J\\, \\dot{\\mathbf{q}}_0^\\text{pref}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\lambda = (J\\, W^{-1} J^T)^{-1} (\\dot{\\mathbf{r}} - J\\, \\dot{\\mathbf{q}}_0^\\text{pref})\n",
    "$$\n",
    "\n",
    "Now we can substitute this in the equation for $\\dot{\\mathbf{q}}$:\n",
    "\n",
    "$$\n",
    "\\dot{\\mathbf{q}} = W^{-1} J^T (J\\, W^{-1} J^T)^{-1} (\\dot{\\mathbf{r}} - J\\, \\dot{\\mathbf{q}}_0^\\text{pref}) + \\dot{\\mathbf{q}}_0^\\text{pref}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\dot{\\mathbf{q}} = J^+ \\dot{\\mathbf{r}} + (I - J^+ J) \\dot{\\mathbf{q}}_0^\\text{pref}\n",
    "$$\n",
    "\n",
    "where $J^+ = W^{-1} J^T (J\\, W^{-1} J^T)^{-1}$ is the weighted pseudoinverse.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of Lagrange Multipliers\n",
    "\n",
    "**Problem:** maximize $f(x, y) = x^2 + y^2$ subject to $g(x, y) = x + y - 1 = 0$\n",
    "\n",
    "In a more formal way, we can write the problem as:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\max_{x, y} &\\quad f(x, y) = x^2 + y^2 \\\\\n",
    "\\text{subject to} &\\quad g(x, y) = x + y - 1 = 0\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "1. Define the Lagrangian function:\n",
    "    $$\\mathcal{L}(x, y, \\lambda) = x^2 + y^2 - \\lambda (x + y - 1)$$\n",
    "2. Compute the gradient of the Lagrangian:\n",
    "    $$\\nabla \\mathcal{L} = \\begin{bmatrix} \\frac{\\partial \\mathcal{L}}{\\partial x} \\\\ \\frac{\\partial \\mathcal{L}}{\\partial y} \\\\ \\frac{\\partial \\mathcal{L}}{\\partial \\lambda} \\end{bmatrix} = \\begin{bmatrix} 2x - \\lambda \\\\ 2y - \\lambda \\\\ x + y - 1 \\end{bmatrix}$$\n",
    "3. Solve the system of equations:\n",
    "    $$\\begin{cases} 2x - \\lambda = 0 \\\\ 2y - \\lambda = 0 \\\\ x + y - 1 = 0 \\end{cases}$$\n",
    "    $$\\begin{cases} x = \\frac{1}{2} \\\\ y = \\frac{1}{2} \\end{cases}$$\n",
    "\n",
    "So, the solution is $x = \\frac{1}{2}$ and $y = \\frac{1}{2}$.     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lecture 8, part 2\n",
    "\n",
    "For a manipulator with $n$ degrees of freedom we use the generalized coordinates\n",
    "\n",
    "$$\n",
    "q = \\begin{bmatrix} q_1 \\\\ q_2 \\\\ \\vdots \\\\ q_n \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "To write the system in the Lagrangian formalism we have to write a function in terms of the kinetic energy $T$ and the potential energy $U$:\n",
    "\n",
    "$$\n",
    "L(q, \\dot{q}) = T(q, \\dot{q}) - U(q)\n",
    "$$\n",
    "\n",
    "Starting from the kinetic energy of a manipulator, this can be written as:\n",
    "\n",
    "$$\n",
    "T(q, \\dot{q}) = \\frac{1}{2} \\dot{q}^T M(q) \\dot{q}\n",
    "$$\n",
    "\n",
    "where $M(q)$ is the mass matrix of the manipulator.\n",
    "\n",
    "For the potetntial energy, that depends only on the particular configuration of the manipulator, so the positions of the center of mass of the links, we can write:\n",
    "\n",
    "$$\n",
    "U(q) = \\sum_{i=1}^n U_i(q) = - \\sum_{i=1}^n m_i g^T r_{c,i}(q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of a 2-link planar robot\n",
    "\n",
    "1. Fisrt link is prismatic with variable $q_1$\n",
    "2. Second link is revolute with variable $q_2$\n",
    "3. The robots works in a vertical plane, so gravity plays a role\n",
    "\n",
    "### Kinetic energy of link 1 and link 2\n",
    "\n",
    "The first link is prismatic, so the kinetic energy is:\n",
    "\n",
    "$$\n",
    "T_1 = \\frac{1}{2} m_1 \\dot{q}_1^2\n",
    "$$\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
